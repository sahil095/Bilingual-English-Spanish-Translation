# ğŸŒ Transformer-based English to Spanish Machine Translation

A complete machine translation pipeline using the Transformer architecture from the paper ["Attention is All You Need"](https://arxiv.org/abs/1706.03762), built from scratch in PyTorch.

This project supports:
- ğŸ§  End-to-end training on a open source English to Spanish translations dataset
- ğŸ“Š Evaluation with BLEU and ROUGE using Hugging Face's `evaluate`
- ğŸ’¬ Streamlit demo for real-time translation
- ğŸ” Attention visualization (optional)
- ğŸ” Beam search decoding
- â˜ï¸ Push to Hugging Face Hub for open source sharing (pending)

---

## ğŸš€ Project Structure

```bash
.
â”œâ”€â”€ app.py                     # Streamlit web UI
â”œâ”€â”€ train.py                  # Training loop with evaluation and checkpointing
â”œâ”€â”€ translation_model.py      # Core Transformer architecture & utilities
â”œâ”€â”€ english_spanish.csv       # Dataset
â”œâ”€â”€ requirements.txt           # Requirements file 
â””â”€â”€ README.md

ğŸ§  Model Architecture
This is a classic encoder-decoder Transformer, built using PyTorch:

- Multi-Head Self-Attention
- Positional Encoding
- Layer Normalization
- Masked Decoding
- Beam Search & Greedy Decoding

The model was trained on ~300,000 English-Spanish pairs.

