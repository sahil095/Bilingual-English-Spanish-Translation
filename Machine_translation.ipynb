{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfcb92c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5141d04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/ssehg1@cfreg.local/.conda/envs/blip/lib/python3.11/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkAddData_12_1, version libnvJitLink.so.12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/blip/lib/python3.11/site-packages/torch/__init__.py:290\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[1;32m    289\u001b[0m         _load_global_deps()\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# torch._C module initialization code in C\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[0;31mImportError\u001b[0m: /home/ssehg1@cfreg.local/.conda/envs/blip/lib/python3.11/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkAddData_12_1, version libnvJitLink.so.12"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ced3a6",
   "metadata": {},
   "source": [
    "## Transformer Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Tokenizer and Vocab ===\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, texts, min_freq=1):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(tokenize(text))\n",
    "\n",
    "        self.itos = ['<pad>', '<sos>', '<eos>', '<unk>'] + [word for word, freq in counter.items() if freq >= min_freq]\n",
    "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
    "\n",
    "    def encode(self, text):\n",
    "        return [1] + [self.stoi.get(tok, self.stoi['<unk>']) for tok in tokenize(text)] + [2]\n",
    "\n",
    "    def decode(self, indices):\n",
    "        return ' '.join([self.itos[i] for i in indices if i not in [0, 1, 2]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "\n",
    "# === Dataset and Dataloader ===\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_texts, tgt_texts, src_vocab, tgt_vocab):\n",
    "        self.src = src_texts\n",
    "        self.tgt = tgt_texts\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_vocab.encode(self.src[idx])), torch.tensor(self.tgt_vocab.encode(self.tgt[idx]))\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "# === Positional Encoding ===\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe_buffer', self.pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe_buffer[:, :x.size(1)]\n",
    "\n",
    "\n",
    "# === Attention and Transformer ===\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # self.qkv = nn.Linear(d_model * 3, d_model * 3)\n",
    "        self.q_linear = nn.Linear(d_model, d_model) # Create separate linear layers for q, k, and v\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None, kv=None):\n",
    "        if kv is None:\n",
    "            kv = x\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "\n",
    "        # qkv = self.qkv(torch.cat([x, kv, kv], dim=-1))\n",
    "        # q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        # q = q.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        # k = k.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        # v = v.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        q = self.q_linear(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(kv).view(batch_size, kv.size(1), self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(kv).view(batch_size, kv.size(1), self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.d_k ** 0.5\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attn, v).transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
    "        return self.out(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=2048):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.norm1(x + self.attn(x, mask))\n",
    "        return self.norm2(x + self.ff(x))\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, enc_out, tgt_mask, src_mask):\n",
    "        x = self.norm1(x + self.self_attn(x, tgt_mask))\n",
    "        x = self.norm2(x + self.cross_attn(x, src_mask, enc_out))\n",
    "        return self.norm3(x + self.ff(x))\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, num_heads=8, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, num_heads) for _ in range(num_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, num_heads) for _ in range(num_layers)])\n",
    "        self.out = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        x = self.pos_enc(self.src_embed(src))\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x, src_mask)\n",
    "        return x\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask, src_mask):\n",
    "        x = self.pos_enc(self.tgt_embed(tgt))\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x, memory, tgt_mask, src_mask)\n",
    "        return self.out(x)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        return self.decode(tgt, memory, tgt_mask, src_mask)\n",
    "\n",
    "\n",
    "# === Masks ===\n",
    "def create_mask(seq, pad_idx=0):\n",
    "    return (seq != pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "def create_subsequent_mask(size):\n",
    "    return torch.tril(torch.ones((size, size), dtype=torch.bool))\n",
    "\n",
    "\n",
    "# === Training ===\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        src_mask = create_mask(src).to(device)\n",
    "        tgt_mask = create_mask(tgt_input).to(device) & create_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), tgt_output.reshape(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def evaluate(model, dataloader, src_vocab, tgt_vocab, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    refs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src = src.to(device)\n",
    "            src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "            memory = model.encode(src, src_mask)\n",
    "\n",
    "            ys = torch.ones(src.size(0), 1).fill_(1).long().to(device)  # <sos>\n",
    "\n",
    "            for _ in range(30):  # max length\n",
    "                tgt_mask = create_subsequent_mask(ys.size(1)).to(device)\n",
    "                out = model.decode(ys, memory, tgt_mask, src_mask)\n",
    "                next_word = out[:, -1].argmax(-1).unsqueeze(1)\n",
    "                ys = torch.cat([ys, next_word], dim=1)\n",
    "                if torch.all(next_word == 2):  # all <eos>\n",
    "                    break\n",
    "\n",
    "            for pred_seq, true_seq in zip(ys, tgt):\n",
    "                pred_text = tgt_vocab.decode(pred_seq.cpu().tolist())\n",
    "                true_text = tgt_vocab.decode(true_seq.cpu().tolist())\n",
    "\n",
    "                preds.append(pred_text)\n",
    "                refs.append(true_text)\n",
    "\n",
    "    # Evaluate with Hugging Face\n",
    "    bleu = bleu_metric.compute(predictions=preds, references=[[r] for r in refs])['bleu']\n",
    "    rouge = rouge_metric.compute(predictions=preds, references=refs)['rougeL']\n",
    "\n",
    "    return bleu, rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea62e17",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a897ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load your dataset ===\n",
    "df = pd.read_csv(\"/home/ssehg1@cfreg.local/Bilingual-English-Spanish-Translation/df_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a037aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Split and tokenize ===\n",
    "train_src, val_src, train_tgt, val_tgt = train_test_split(df[\"english\"], df[\"spanish\"], test_size=0.1, random_state=42)\n",
    "\n",
    "eng_vocab = Vocab(train_src.tolist())\n",
    "spa_vocab = Vocab(train_tgt.tolist())\n",
    "\n",
    "train_dataset = TranslationDataset(train_src.tolist(), train_tgt.tolist(), eng_vocab, spa_vocab)\n",
    "val_dataset = TranslationDataset(val_src.tolist(), val_tgt.tolist(), eng_vocab, spa_vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# === Set up model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Transformer(len(eng_vocab), len(spa_vocab), d_model=256).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6b023",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training loop ===\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    bleu, rouge = evaluate(model, val_loader, eng_vocab, spa_vocab, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, BLEU = {bleu:.4f}, ROUGE-L = {rouge:.4f}\")\n",
    "\n",
    "# === Save model and vocabs ===\n",
    "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
    "torch.save(eng_vocab, \"eng_vocab.pth\")\n",
    "torch.save(spa_vocab, \"spa_vocab.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad4fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea4874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16132048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa75b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28471d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32463867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74476f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac006859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f0e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b06c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c989a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
